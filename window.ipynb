{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff0943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "\n",
    "# Load YOLOv3 model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize speech recognition\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Global variable to control the detection loop\n",
    "detecting = False\n",
    "\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Preprocess the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                label = str(classes[class_id])\n",
    "                detected_objects.append(label)\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def speak_detected_objects(objects):\n",
    "    if len(objects) == 0:\n",
    "        engine.say(\"No objects detected.\")\n",
    "    else:\n",
    "        object_str = \", \".join(objects)\n",
    "        engine.say(f\"I see {object_str}\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "def voice_command():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for commands...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio).lower()\n",
    "            print(\"Command:\", command)\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Google Speech Recognition request failed: {e}\")\n",
    "            return None\n",
    "\n",
    "def object_detection_loop():\n",
    "    global detecting\n",
    "    # Initialize video capture (replace 0 with your desired camera index)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if the camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video capture.\")\n",
    "        engine.say(\"Error: Unable to open video capture.\")\n",
    "        engine.runAndWait()\n",
    "        return\n",
    "\n",
    "    engine.say(\"Object detection started. Say 'stop' to stop detection.\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "    while detecting:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame.\")\n",
    "            engine.say(\"Error: Unable to capture frame.\")\n",
    "            engine.runAndWait()\n",
    "            break\n",
    "\n",
    "        # Perform object detection\n",
    "        new_objects = detect_objects(frame)\n",
    "\n",
    "        # Speak out detected objects\n",
    "        speak_detected_objects(new_objects)\n",
    "\n",
    "        # Wait a bit before the next detection\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    # Release the video capture and close the text-to-speech engine\n",
    "    cap.release()\n",
    "    engine.say(\"Object detection stopped.\")\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n",
    "\n",
    "def start_detection():\n",
    "    global detecting\n",
    "    if not detecting:\n",
    "        detecting = True\n",
    "        detection_thread = threading.Thread(target=object_detection_loop)\n",
    "        detection_thread.start()\n",
    "        print(\"Detection started\")\n",
    "    else:\n",
    "        print(\"Detection already running\")\n",
    "\n",
    "def stop_detection():\n",
    "    global detecting\n",
    "    detecting = False\n",
    "    print(\"Detection stopped\")\n",
    "\n",
    "def voice_control_loop():\n",
    "    while True:\n",
    "        command = voice_command()\n",
    "        if command == \"start\":\n",
    "            start_detection()\n",
    "        elif command == \"stop\":\n",
    "            stop_detection()\n",
    "            break\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Object Detection Application\")\n",
    "\n",
    "# Label to show instructions\n",
    "label = tk.Label(root, text=\"Use voice commands 'start' and 'stop' to control object detection.\", font=(\"Arial\", 14))\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Start the voice control loop in a separate thread\n",
    "voice_thread = threading.Thread(target=voice_control_loop)\n",
    "voice_thread.start()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64280550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Command: start\n",
      "Detection started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\Admin\\anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\Users\\Admin\\anaconda3\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23836\\2707426348.py\", line 87, in object_detection_loop\n",
      "  File \"D:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pyttsx3\\engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for commands...\n",
      "Command: exception is\n",
      "Listening for commands...\n",
      "Command: extension in canada\n",
      "Listening for commands...\n",
      "Command: 47\n",
      "Command: 47\n",
      "Listening for commands...\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Command: set timer for\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n",
      "Could not understand audio.\n",
      "Listening for commands...\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "\n",
    "# Load YOLOv3 model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Initialize speech recognition\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Global variable to control the detection loop\n",
    "detecting = False\n",
    "\n",
    "def detect_objects(frame):\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Preprocess the frame for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    detected_objects = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                label = str(classes[class_id])\n",
    "                detected_objects.append(label)\n",
    "\n",
    "    return detected_objects\n",
    "\n",
    "def speak_detected_objects(objects):\n",
    "    if len(objects) == 0:\n",
    "        engine.say(\"No objects detected.\")\n",
    "    else:\n",
    "        object_str = \", \".join(objects)\n",
    "        engine.say(f\"I see {object_str}\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "def voice_command():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for commands...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio).lower()\n",
    "            print(\"Command:\", command)\n",
    "            return command\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Google Speech Recognition request failed: {e}\")\n",
    "            return None\n",
    "\n",
    "def object_detection_loop():\n",
    "    global detecting\n",
    "    # Initialize video capture (replace 0 with your desired camera index)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if the camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video capture.\")\n",
    "        engine.say(\"Error: Unable to open video capture.\")\n",
    "        engine.runAndWait()\n",
    "        return\n",
    "\n",
    "    engine.say(\"Object detection started. Say 'stop' to stop detection.\")\n",
    "    engine.runAndWait()\n",
    "\n",
    "    while detecting:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture frame.\")\n",
    "            engine.say(\"Error: Unable to capture frame.\")\n",
    "            engine.runAndWait()\n",
    "            break\n",
    "\n",
    "        # Perform object detection\n",
    "        new_objects = detect_objects(frame)\n",
    "\n",
    "        # Speak out detected objects\n",
    "        speak_detected_objects(new_objects)\n",
    "\n",
    "        # Wait a bit before the next detection\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    # Release the video capture and close the text-to-speech engine\n",
    "    cap.release()\n",
    "    engine.say(\"Object detection stopped.\")\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n",
    "\n",
    "def start_detection():\n",
    "    global detecting\n",
    "    if not detecting:\n",
    "        detecting = True\n",
    "        detection_thread = threading.Thread(target=object_detection_loop)\n",
    "        detection_thread.start()\n",
    "        print(\"Detection started\")\n",
    "        engine.say(\"Detection started\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        print(\"Detection already running\")\n",
    "        engine.say(\"Detection already running\")\n",
    "        engine.runAndWait()\n",
    "\n",
    "def stop_detection():\n",
    "    global detecting\n",
    "    if detecting:\n",
    "        detecting = False\n",
    "        print(\"Detection stopped\")\n",
    "        engine.say(\"Detection stopped\")\n",
    "        engine.runAndWait()\n",
    "    else:\n",
    "        print(\"Detection is not running\")\n",
    "        engine.say(\"Detection is not running\")\n",
    "        engine.runAndWait()\n",
    "\n",
    "def voice_control_loop():\n",
    "    while True:\n",
    "        command = voice_command()\n",
    "        if command == \"start\":\n",
    "            start_detection()\n",
    "        elif command == \"stop\":\n",
    "            stop_detection()\n",
    "            break\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Object Detection Application\")\n",
    "\n",
    "# Label to show instructions\n",
    "label = tk.Label(root, text=\"Use voice commands 'start' and 'stop' to control object detection.\", font=(\"Arial\", 14))\n",
    "label.pack(pady=20)\n",
    "\n",
    "# Start the voice control loop in a separate thread\n",
    "voice_thread = threading.Thread(target=voice_control_loop)\n",
    "voice_thread.start()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7236126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e4af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e44e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
